{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject #4</div>\n",
    "<span style=\"\">MicroProject: Highest Mountains in the World</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/04-highest-mountain/\">https://discovery.cs.illinois.edu/microproject/04-highest-mountain/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source: Wikipedia's \"List of mountains by elevation\"\n",
    "\n",
    "Wikipedia is an absolutely amazing source of information about almost every topic you can imagine!  In this microproject, you will explore how to easily use data in Wikipedia tables as datasets.\n",
    "\n",
    "The Wikipedia article \"[List of mountains by elevation](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation) contains information on hundreds of mountains -- including Mount Everest (tallest in the world), Denali (tallest in the United States), and many more!\n",
    "- Click the link above [(or right here)]((https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)) to view how the Wikipedia page looks in your web browser!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using pandas `read_html` function\n",
    "\n",
    "The `pd.read_html(...)` function in the pandas library is designed to read data from tables found in webpages.\n",
    "- `read_html` is very similar to the more commonly used `read_csv`\n",
    "- Instead of returning a DataFrame like `read_csv`, the `read_html` returns a **list of DataFrames** -- one DataFrame for each table!\n",
    "- Just like `read_csv`, you only need to provide the URL of the data!\n",
    "\n",
    "Import `pandas` and create a new variable called `pages` the reads in all of tables on the Wikipedia page  \"[List of mountains by elevation](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSIGNMENT CODE for Data Import ==\n",
    "\n",
    "import pandas as pd\n",
    "pages = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_mountains_by_elevation\")\n",
    "pages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Checkpoint Tests 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Data Import ==\n",
    "## == CHECKPOINT TESTS ==\n",
    "# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n",
    "# - If this cell results in a celebration message, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"pages\" in vars())\n",
    "assert(type(pages[0]) == type(pd.DataFrame()))\n",
    "assert(\"Feet\" in pages[0])\n",
    "assert(\"Range\" in pages[1])\n",
    "assert(\"Mountain\" in pages[2])\n",
    "assert(\"Location and Notes\" in pages[3])\n",
    "assert(\"Metres\" in pages[4])\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joining the individual DataFrames into one large DataFrame\n",
    "\n",
    "Now that you have **ALL** of the tables in the `pages` variable, we want to convert this into one large DataFrame.  However, instead of having just one DataFrame, the webpage has different tables.\n",
    "\n",
    "Let's explore the individual tables.  Using `pages[0]`, you can view the first table of data found on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using `pages[1]`, you view the second table that was found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding the Last DataFrame\n",
    "\n",
    "Continue to look at the tables the Wikipedia page contains.  Find out the **last index** of `pages` that contains data amount the mountains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining the DataFrames Together\n",
    "\n",
    "Before we can do analysis on the whole dataset, we need to join the individual tables together.  When we join DataFrames end-to-end, where the last row of the previous DataFrame is followed by the first row of the next DataFrame, the operation is called concatenation.\n",
    "\n",
    "Read the DISCOVERY guide to learn the syntax on \"Combining DataFrames by Concatenation\"\n",
    "- [Guide: \"Combining DataFrames by Concatenation\"](https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/) (https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/)\n",
    "\n",
    "Use concatenation to create a single DataFrame `df` that contains data amount every mountain found on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSIGNMENT CODE for Data Merging ==\n",
    "\n",
    "df = pd.concat( [pages[0], pages[1], pages[2], pages[3], pages[4], pages[5], pages[6], pages[7], pages[8]] )\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Checkpoint Tests 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Data Merging ==\n",
    "## == CHECKPOINT TESTS ==\n",
    "# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n",
    "# - If this cell results in a celebration message, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df\" in vars())\n",
    "assert(len(df) > len(pages[0]))\n",
    "assert(\"Feet\" in df)\n",
    "assert(\"Mountain\" in df)\n",
    "assert(len(df[df.Feet > 26000]) > 0)\n",
    "assert(len(df[df.Feet < 2000]) > 0)\n",
    "assert(len(df[ (df.Feet < 26000) & (df.Feet > 22000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 22000) & (df.Feet > 18000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 18000) & (df.Feet > 14000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 14000) & (df.Feet > 10000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 10000) & (df.Feet > 6000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 6000) & (df.Feet > 2000) ]) > 0)\n",
    "print(f\"{tada} All Tests Passed! {tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mountains in the United States\n",
    "\n",
    "Now that we have every mountain in a single DataFrame, we can do some analysis!  In the dataset, the `Location and Notes` column contains a human-written description of the location and other notes.\n",
    "\n",
    "Create a DataFrame called `df_us` that contains all of the mountains in the United States.\n",
    "\n",
    "- You will need to look back at the [Wikipedia page]((https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/)), or explore `df` here in Python, to find out all the different ways mountains in the United States might be labeled.  *(Hint: There's two different ways!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSIGNMENT CODE for Mountains ==\n",
    "\n",
    "df_us = df[\n",
    "  df[\"Location and Notes\"].str.contains(\"US\") |\n",
    "  df[\"Location and Notes\"].str.contains(\"United States\")\n",
    "]\n",
    "df_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Percentage of Mountains in the Dataset in the United States?\n",
    "\n",
    "What percentage of mountains in the entire dataset is found in the United States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSIGNMENT CODE for Mountains ==\n",
    "\n",
    "pct_us = len(df_us) / len(df)\n",
    "pct_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Checkpoint Tests 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Mountains ==\n",
    "## == CHECKPOINT TESTS ==\n",
    "# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n",
    "# - If this cell results in a celebration message, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df_us\" in vars())\n",
    "assert(len(df_us) > 300)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Mount Saint Elias\")]) == 1)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Denali\")]) == 1)\n",
    "\n",
    "assert(\"pct_us\" in vars())\n",
    "assert(pct_us == len(df_us) / len(df))\n",
    "\n",
    "print(f\"{tada} DataFrame Analysis: All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🔬 Microproject - All Checkpoint 🔬\n",
    "\n",
    "The final check is that you pass all the tests, all at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Final Checkpoint ==\n",
    "## == CHECKPOINT TESTS ==\n",
    "# - This read-only cell contains a \"checkpoint\" for the MicroProejct and verifies you are on the right track.\n",
    "# - If this cell results in a celebration message, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"pages\" in vars())\n",
    "assert(type(pages[0]) == type(pd.DataFrame()))\n",
    "assert(\"Feet\" in pages[0])\n",
    "assert(\"Range\" in pages[1])\n",
    "assert(\"Mountain\" in pages[2])\n",
    "assert(\"Location and Notes\" in pages[3])\n",
    "assert(\"Metres\" in pages[4])\n",
    "\n",
    "assert(\"df\" in vars())\n",
    "assert(len(df) > len(pages[0]))\n",
    "assert(\"Feet\" in df)\n",
    "assert(\"Mountain\" in df)\n",
    "assert(len(df[df.Feet > 26000]) > 0)\n",
    "assert(len(df[df.Feet < 2000]) > 0)\n",
    "assert(len(df[ (df.Feet < 26000) & (df.Feet > 22000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 22000) & (df.Feet > 18000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 18000) & (df.Feet > 14000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 14000) & (df.Feet > 10000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 10000) & (df.Feet > 6000) ]) > 0)\n",
    "assert(len(df[ (df.Feet < 6000) & (df.Feet > 2000) ]) > 0)\n",
    "\n",
    "assert(\"df_us\" in vars())\n",
    "assert(len(df_us) > 300)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Mount Saint Elias\")]) == 1)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Denali\")]) == 1)\n",
    "\n",
    "assert(\"pct_us\" in vars())\n",
    "assert(pct_us == len(df_us) / len(df))\n",
    "\n",
    "print(f\"{tada}{tada} All Tests Passed! {tada}{tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  ⚠️ **Make certain to save your work.** ⚠️ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and follow the instructions to commit and grade this MicroProject on GitHub!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
